# -*- coding: utf-8 -*-
"""5 - Chi Square For Feature Selection 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1skT036fu0uZABm_J4vKJKg1Hp6bAKl4V

### Fisher Score- Chisquare  Test For Feature Selection

Compute chi-squared stats between each non-negative feature and class.

- This score should be used to evaluate categorical variables in a classification task.

This score can be used to select the n_features features with the highest values for the test chi-squared statistic from X, which must contain only non-negative features such as booleans or frequencies (e.g., term counts in document classification), relative to the classes.

Recall that the chi-square test measures dependence between stochastic variables, so using this function “weeds out” the features that are the most likely to be independent of class and therefore irrelevant for classification.
The Chi Square statistic is commonly used for testing relationships between categorical variables.

It compares the observed distribution of the different classes of target Y among the different categories of the feature, against the expected distribution of the target classes, regardless of the feature categories.
"""

import seaborn as sns
df=sns.load_dataset('titanic')

df.head()

df.info()

##['sex','embarked','alone','pclass','Survived']
df=df[['sex','embarked','alone','pclass','survived']]
df.head()

import numpy as np
### Let's perform label encoding on sex column
df['sex']=np.where(df['sex']=="male",1,0)
df.head()

### let's perform label encoding on embarked
ordinal_label = {k: i for i, k in enumerate(df['embarked'].unique(), 0)}
df['embarked'] = df['embarked'].map(ordinal_label)

ordinal_label

df.head()

### let's perform label encoding on alone
df['alone']=np.where(df['alone']==True,1,0)

df.head()

### train Test split is usually done to avoid overfitting
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(df[['sex','embarked','alone','pclass']],
                                              df['survived'],test_size=0.3,random_state=100)

X_train.head()

X_train['sex'].unique()

X_train.isnull().sum()

## Perform chi2 test
### chi2 returns 2 values
### Fscore and the pvalue
from sklearn.feature_selection import chi2
f_p_values=chi2(X_train,y_train)

f_p_values

import pandas as pd
p_values=pd.Series(f_p_values[1])
p_values.index=X_train.columns
p_values

p_values.sort_index(ascending=False)

"""### Observation
Sex Column is the most important column when compared to the output feature
Survived
"""



